\section{Introduction}
Humans have always been limited in their capacity and knowledge. There are problems that we cannot solve by brain power alone. The first computers came therefore into existence, made to do tasks that we found too heavy, tedious or even difficult. Today, this has become more of a reliance than ever. Computers has not only become ridiculously faster but also practically omnipresent. Whether we like it or not, it has become essential for a modern society.

However, the problem with computers, just like it was aeons ago, is that it still needs to be told what to do. It still fails when there is a need for adaptation and ingenuity, unless explicitly programmed for it. Even then, it would be near impossible to predict every little situation that has the slightest chance to occur. There is a need to make computers adapt. There are several ways to accomplish this but discussing them all is outside the scope of this thesis. Instead, we shall focus on one particular area, genetic algorithms.

While this relatively new method has been applied in various applications already, there are still aspects of it that need to addressed. One major concern is that of scalability. Some years ago, the most common way to map a genotype to phenotype was often directly. Altering a single trait in the genotype had an effect on one trait in the phenotype. For small applications, this was fine. As problems increased in size and complexity, the genotype too became larger and more complex. Since genetic algorithms are inspired by natural selection, it is only obvious that possible solutions to the scalability problem could also stem from biology. Drawing inspiration from genome and cellular activities, many development models have been created but it is difficult to learn from it. How can we see what works and what doesn't? When these models are built individually, on different platforms, how do we then know what is right when they give contradictory results? How do we know it is not the model that is at fault but a smaller detail somewhere else?

This thesis does not seek to answer such questions. Instead, it proposes a common platform on which models can be implemented. This framework is an attempt at eliminating trivial factors that aren't important in the big picture. The focus should lie on the models and not the underlying structure upon which it was implemented.

In the following section, we will have a look at the two models that have been chosen for this project. We will look at the idea behind them and see how they work. We will also discuss their differences and explain why a framework is necessary. In chapter~\ref{sec:implementation}, we shall take a look at the implementation of the framework and the porting of mentioned models over to the framework. This section will describe the most important details that is relevant to their re-implementation. Any changes made during this process will be highlighted and explained. Chapter~\ref{sec:experiments} will take us back to past experiments. We will be looking at some results of experiments that have been repeated in order verify that the new implementations are able to perform at least as well as the original implementations did.
